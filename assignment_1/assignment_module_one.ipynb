{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Members\n",
    "\n",
    "* **Student ID:** 0001111416  \n",
    "  **Full Name:** Alessio Pittiglio  \n",
    "  **Institutional Email:** alessio.pittiglio@studio.unibo.it\n",
    "\n",
    "* **Student ID:** 0001086355  \n",
    "  **Full Name:** Parsa Mastouri Kashani  \n",
    "  **Institutional Email:** parsa.mastouri@studio.unibo.it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Product Recognition of Books**\n",
    "\n",
    "## Image Processing and Computer Vision - Assignment Module \\#1\n",
    "\n",
    "\n",
    "Contacts:\n",
    "\n",
    "- Prof. Giuseppe Lisanti -> giuseppe.lisanti@unibo.it\n",
    "- Prof. Samuele Salti -> samuele.salti@unibo.it\n",
    "- Alex Costanzino -> alex.costanzino@unibo.it\n",
    "- Francesco Ballerini -> francesco.ballerini4@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer vision-based object detection techniques can be applied in library or bookstore settings to build a system that identifies books on shelves.\n",
    "\n",
    "Such a system could assist in:\n",
    "* Helping visually impaired users locate books by title/author;\n",
    "* Automating inventory management (e.g., detecting misplaced or out-of-stock books);\n",
    "* Enabling faster book retrieval by recognizing spine text or cover designs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Develop a computer vision system that, given a reference image for each book, is able to identify such book from one picture of a shelf.\n",
    "\n",
    "<figure>\n",
    "<a href=\"https://ibb.co/pvLVjbM5\"><img src=\"https://i.ibb.co/svVx9bNz/example.png\" alt=\"example\" border=\"0\"></a>\n",
    "</figure>\n",
    "\n",
    "For each type of product displayed on the shelf, the system should compute a bounding box aligned with the book spine or cover and report:\n",
    "1. Number of instances;\n",
    "1. Dimension of each instance (area in pixel of the bounding box that encloses each one of them);\n",
    "1. Position in the image reference system of each instance (four corners of the bounding box that enclose them);\n",
    "1. Overlay of the bounding boxes on the scene images.\n",
    "\n",
    "<font color=\"red\"><b>Each step of this assignment must be solved using traditional computer vision techniques.</b></font>\n",
    "\n",
    "#### Example of expected output\n",
    "```\n",
    "Book 0 - 2 instance(s) found:\n",
    "  Instance 1 {top_left: (100,200), top_right: (110, 220), bottom_left: (10, 202), bottom_right: (10, 208), area: 230px}\n",
    "  Instance 2 {top_left: (90,310), top_right: (95, 340), bottom_left: (24, 205), bottom_right: (23, 234), area: 205px}\n",
    "Book 1 â€“ 1 instance(s) found:\n",
    ".\n",
    ".\n",
    ".\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Two folders of images are provided:\n",
    "* **Models**: contains one reference image for each product that the system should be able to identify;\n",
    "* **Scenes**: contains different shelve pictures to test the developed algorithm in different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !cp -r /content/drive/MyDrive/AssignmentsIPCV/dataset.zip ./\n",
    "# !unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation criteria\n",
    "1. **Clarity and conciseness**. Present your work in a readable way: format your code and comment every important step;\n",
    "\n",
    "2. **Procedural correctness**. There are several ways to solve the assignment. Design your own sound approach and justify every decision you make;\n",
    "\n",
    "3. **Correctness of results**. Try to solve as many instances as possible. You should be able to solve all the instances of the assignment, however, a thoroughly justified and sound procedure with a lower number of solved instances will be valued **more** than a poorly designed and justified approach that solves more or all instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ght_sift_lib import SIFT_GHT_Detector, natural_sort_key, format_and_print_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = os.path.join(\"dataset\", \"models\")\n",
    "SCENES_DIR = os.path.join(\"dataset\", \"scenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = SIFT_GHT_Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "model_files = sorted(\n",
    "    [\n",
    "        f\n",
    "        for f in os.listdir(MODELS_DIR)\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ],\n",
    "    key=natural_sort_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(model_files):\n",
    "    book_name = f\"Book {i}\"\n",
    "    models[book_name] = cv2.imread(os.path.join(MODELS_DIR, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_files = sorted(os.listdir(SCENES_DIR), key=natural_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_filename in scene_files:\n",
    "    if not scene_filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    scene_path = os.path.join(SCENES_DIR, scene_filename)\n",
    "    scene_image = cv2.imread(scene_path)\n",
    "    overlay_image = scene_image.copy()\n",
    "\n",
    "    all_scene_detections = {}\n",
    "    for book_name, model_image in models.items():\n",
    "        detections = detector.detect_multiple(model_image, scene_image, verbose=False)\n",
    "\n",
    "        if detections:\n",
    "            all_scene_detections[book_name] = detections\n",
    "            # Draw bounding boxes\n",
    "            for det in detections:\n",
    "                cv2.polylines(\n",
    "                    overlay_image,\n",
    "                    [det[\"corners_list\"]],\n",
    "                    isClosed=True,\n",
    "                    color=(0, 255, 0),\n",
    "                    thickness=2,\n",
    "                )\n",
    "\n",
    "    format_and_print_results(all_scene_detections, scene_filename)\n",
    "\n",
    "    # Display results\n",
    "    plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Detecting instances of a single book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example scene and model\n",
    "scene_filename = scene_files[3]\n",
    "scene_path = os.path.join(SCENES_DIR, scene_filename)\n",
    "scene_image = cv2.imread(scene_path)\n",
    "model_image = models[\"Book 16\"]\n",
    "\n",
    "# Detect and visualize\n",
    "detections = detector.detect_multiple(model_image, scene_image, verbose=False)\n",
    "overlay_image = scene_image.copy()\n",
    "\n",
    "for det in detections:\n",
    "    cv2.polylines(\n",
    "        overlay_image,\n",
    "        [det[\"corners_list\"]],\n",
    "        isClosed=True,\n",
    "        color=(0, 255, 0),\n",
    "        thickness=2,\n",
    "    )\n",
    "\n",
    "plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Detections in {scene_filename}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipcv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
